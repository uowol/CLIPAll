{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'domainbed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alllh\\Documents\\Git\\CLIPAll_on_DPLCLIP\\scripts\\summarize_results.ipynb 셀 1\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alllh/Documents/Git/CLIPAll_on_DPLCLIP/scripts/summarize_results.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alllh/Documents/Git/CLIPAll_on_DPLCLIP/scripts/summarize_results.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alllh/Documents/Git/CLIPAll_on_DPLCLIP/scripts/summarize_results.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdomainbed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m misc, reporting\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alllh/Documents/Git/CLIPAll_on_DPLCLIP/scripts/summarize_results.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdomainbed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquery\u001b[39;00m \u001b[39mimport\u001b[39;00m Q\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alllh/Documents/Git/CLIPAll_on_DPLCLIP/scripts/summarize_results.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdomainbed\u001b[39;00m \u001b[39mimport\u001b[39;00m model_selection\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'domainbed'"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=$PWD\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from domainbed.lib import misc, reporting\n",
    "from domainbed.lib.query import Q\n",
    "from domainbed import model_selection\n",
    "from domainbed import datasets\n",
    "\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from domainbed.scripts.collect_results import print_table, format_mean\n",
    "# from domainbed.lib.query import make_selector_fn\n",
    "\n",
    "import scipy\n",
    "latex = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def load_records(path, file_name):\n",
    "    records = []\n",
    "    for i, subdir in tqdm.tqdm(list(enumerate(os.listdir(path))),\n",
    "                               ncols=80,\n",
    "                               leave=False):\n",
    "        results_path = os.path.join(path, subdir, file_name)\n",
    "        try:\n",
    "            with open(results_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    records.append(json.loads(line[:-1]))\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "    return Q(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_records(records, group_str):\n",
    "    \"\"\"Group records by (trial_seed, dataset, algorithm, test_env). Because\n",
    "    records can have multiple test envs, a given record may appear in more than\n",
    "    one group.\"\"\"\n",
    "    result = collections.defaultdict(lambda: [])\n",
    "    for r in records:\n",
    "        for test_env in r[\"args\"][\"test_envs\"]:\n",
    "            group = list(Q([r]).select(group_str)[0])\n",
    "            group.append(test_env)\n",
    "            group = tuple(group)\n",
    "            result[group].append(r)\n",
    "    group_key = group_str.replace(' ', '').replace('args.','').replace('hparams.', '').split(',') + ['test_env', 'records']\n",
    "    \n",
    "    grouped_records = []\n",
    "    for v, r in result.items():\n",
    "        v = list(v)\n",
    "        v.append(Q(r))\n",
    "        grouped_records.append(dict(zip(group_key, v)))\n",
    "    return Q(grouped_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_print_table(table, header_text, row_labels, col_labels, colwidth=10,\n",
    "    latex=True):\n",
    "    \"\"\"Pretty-print a 2D array of data, optionally with row/col labels\"\"\"\n",
    "    print(\"\")\n",
    "\n",
    "    if latex:\n",
    "        num_cols = len(table[0])\n",
    "        \"\"\"\n",
    "        print(\"\\\\begin{center}\")\n",
    "        print(\"\\\\adjustbox{max width=\\\\textwidth}{%\")\n",
    "        print(\"\\\\begin{tabular}{l\" + \"c\" * num_cols + \"}\")\n",
    "        print(\"\\\\toprule\")\n",
    "        \"\"\"\n",
    "    else:\n",
    "        print(\"--------\", header_text)\n",
    "\n",
    "    for row, label in zip(table, row_labels):\n",
    "        row.insert(0, label)\n",
    "    \n",
    "    \"\"\"\n",
    "    if latex:\n",
    "        col_labels = [\"\\\\textbf{\" + str(col_label).replace(\"%\", \"\\\\%\") + \"}\"\n",
    "            for col_label in col_labels]\n",
    "    table.insert(0, col_labels)\n",
    "    \"\"\"\n",
    "\n",
    "    for r, row in enumerate(table):\n",
    "        misc.print_row(row, colwidth=colwidth, latex=latex)\n",
    "        \"\"\"\n",
    "        if latex and r == 0:\n",
    "            print(\"\\\\midrule\")\n",
    "        \"\"\"\n",
    "    print(\"\\\\midrule\")\n",
    "    \"\"\"\n",
    "    if latex:\n",
    "        print(\"\\\\bottomrule\")\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms = ['FrozenERM']\n",
    "# algorithms = ['ERM', 'CORAL', 'DANN', 'DPLCLIP', 'CLIP', 'WordCLIP']\n",
    "# algorithms = ['ERM', 'CORAL']\n",
    "algorithms = ['ERM']\n",
    "# algorithms = ['DPLCLIP']\n",
    "backbones = ['clip_vitb16']\n",
    "clip_backbones = ['ViT-B/16']\n",
    "hparams = ['{\"backbone\": \"clip\", \"clip_backbone\": \"ViT-B/16\"}', '{\"backbone\": \"clip\", \"clip_backbone\": \"ViT-B/32\"}','{\"backbone\": \"clip\", \"clip_backbone\": \"RN101\"}']\n",
    "# backbones = ['DeiT', 'HViT', 'ViT-B32', 'ViT-B16','resnet50', 'resnet18']\n",
    "tgt_dataset_names = ['VLCS', 'PACS', 'OfficeHome', 'TerraIncognita']\n",
    "tgt_adaptation_names = ['None', 'T3A-64', 'TentClf-64', 'SHOTIM-64', 'PLClf-64', 'SHOT-64', 'PseudoLabel-64']\n",
    "# tgt_adaptation_names = ['None']\n",
    "seeds = [0, 1, 2]\n",
    "records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "### Backbone == clip\n",
    "### clip_backbone == 'ViT-B/16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████▏                    | 3209/6874 [01:32<02:56, 20.71it/s]"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    r = load_records('~/DPLCLIP/{}'.format(backbone), 'results.jsonl')\n",
    "    r = r.filter_in('args.trial_seed', seeds)\n",
    "    r = r.filter_in('args.algorithm', algorithms)\n",
    "    r = r.filter_in('args.hparams', hparams)\n",
    "    r = r.map(lambda r: {**r, \"adapt\": 'None', \"selection_method\": model_selection.IIDAccuracySelectionMethod}) \n",
    "    records += r._list\n",
    "\n",
    "    for tgt_adaptation in tgt_adaptation_names:\n",
    "        r = load_records('~/DPLCLIP/{}'.format(backbone), 'results_{}.jsonl'.format(tgt_adaptation))\n",
    "        r = r.filter_in('args.trial_seed', seeds)\n",
    "        r = r.filter_in('args.algorithm', algorithms)\n",
    "        # r = r.filter_equals('filter_K', 100)\n",
    "        r = r.map(lambda r: {**r, \"adapt\": r['args']['adapt_algorithm'], \"selection_method\": model_selection.IIDAccuracySelectionMethod}) \n",
    "        records += r._list\n",
    "records = Q(records)\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptation_names:  ['None']\n",
      "dataset_names:  ['VLCS', 'PACS', 'OfficeHome', 'TerraIncognita']\n"
     ]
    }
   ],
   "source": [
    "# perpare the.\n",
    "selection_method = model_selection.IIDAccuracySelectionMethod\n",
    "group_str = 'args.trial_seed, args.dataset, args.algorithm, hparams.backbone, adapt'\n",
    "grouped_records = get_grouped_records(records, group_str).map(lambda group:\n",
    "        { **group, \"sweep_acc\": group[\"records\"][0]['selection_method'].sweep_acc(group[\"records\"]) }\n",
    "    ).filter(lambda g: g[\"sweep_acc\"] is not None)\n",
    "\n",
    "adaptation_names = Q(records).select(\"adapt\").unique()\n",
    "dataset_names = Q(records).select(\"args.dataset\").unique().sorted()\n",
    "dataset_names = [d for d in datasets.DATASETS if d in dataset_names]\n",
    "print('adaptation_names: ', adaptation_names)\n",
    "print('dataset_names: ', dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clip']\n",
      "['TerraIncognita']\n",
      "\n",
      "\\subsubsection{TerraIncognita}\n",
      "\n",
      "\\begin{center}\n",
      "\\adjustbox{max width=\\textwidth}{%\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      "\\textbf{Backbone}    & \\textbf{L100}        & \\textbf{L38}         & \\textbf{L43}         & \\textbf{L46}         & \\textbf{Avg}         \\\\\n",
      "\\midrule\n",
      "clip                 & 49.3 $\\pm$ 8.7       & 36.2 $\\pm$ 3.3       & 42.8 $\\pm$ 3.2       & 36.6 $\\pm$ 2.0       & 41.2                 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "backbone_names = Q(records).select(\"backbone\").unique()\n",
    "# alg_names = ([n for n in algorithms.ALGORITHMS if n in alg_names] +\n",
    "#     [n for n in alg_names if n not in algorithms.ALGORITHMS])\n",
    "print(backbone_names)\n",
    "# # read dataset names and sort (lexicographic order)\n",
    "dataset_names = Q(records).select(\"dataset\").unique().sorted()\n",
    "print(dataset_names)\n",
    "dataset_names = [d for d in datasets.DATASETS if d in dataset_names]\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    if latex:\n",
    "        print()\n",
    "        print(\"\\\\subsubsection{{{}}}\".format(dataset))\n",
    "    test_envs = range(datasets.num_environments(dataset))\n",
    "\n",
    "    table = [[None for _ in [*test_envs, \"Avg\"]] for _ in backbone_names]\n",
    "    for i, backbone in enumerate(backbone_names):\n",
    "        means = []\n",
    "        for j, test_env in enumerate(test_envs):\n",
    "            trial_accs = (grouped_records\n",
    "                .filter_equals(\n",
    "                    \"dataset, backbone, test_env\",\n",
    "                    (dataset, backbone, test_env)\n",
    "                ).select(\"sweep_acc\"))\n",
    "            mean, err, table[i][j] = format_mean(trial_accs, latex)\n",
    "            means.append(mean)\n",
    "        if None in means:\n",
    "            table[i][-1] = \"X\"\n",
    "        else:\n",
    "            table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "\n",
    "    col_labels = [\n",
    "        \"Backbone\", \n",
    "        *datasets.get_dataset_class(dataset).ENVIRONMENTS,\n",
    "        \"Avg\"\n",
    "    ]\n",
    "    header_text = (f\"Dataset: {dataset}, \"\n",
    "        f\"model selection method: {selection_method.name}\")\n",
    "    print_table(table, header_text, backbone_names, list(col_labels),\n",
    "        colwidth=20, latex=latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish backbone:  ERM VLCS 12 clip\n",
      "Finish backbone:  ERM PACS 12 clip\n",
      "Finish backbone:  ERM OfficeHome 12 clip\n",
      "Finish backbone:  ERM TerraIncognita 12 clip\n",
      "Did not finish, ERROR!!!!! 0 CORAL VLCS clip\n",
      "Did not finish, ERROR!!!!! 4 CORAL PACS clip\n",
      "Finish backbone:  CORAL OfficeHome 12 clip\n",
      "Finish backbone:  CORAL TerraIncognita 12 clip\n"
     ]
    }
   ],
   "source": [
    "# def check_records(records):\n",
    "#     for rec in records:\n",
    "#         for r in rec['records']:\n",
    "#             print(r)\n",
    "#         # assert len(rec) == 360\n",
    "\n",
    "# # Check the data missing.\n",
    "# # if len() == 60 : backbone + 4 tta methods. \n",
    "# # elif: len() == 12 : backbone only. \n",
    "# else: ERROR.\n",
    "for backbone in backbones:\n",
    "    for algo in algorithms:\n",
    "        for dataset in dataset_names:\n",
    "            records = grouped_records.filter_equals(\"dataset, algorithm, backbone\", (dataset, algo, backbone))\n",
    "            if len(records) == 84:\n",
    "                print('Finish all experiment: backbone + 6 TTA methods', algo, dataset, len(records), backbone)\n",
    "                # check_records(records)\n",
    "            elif len(records) == 12:\n",
    "                print('Finish backbone: ', algo, dataset, len(records), backbone)\n",
    "            else:\n",
    "                print('Did not finish, ERROR!!!!!', len(records), algo, dataset, backbone)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# # for algo in algorithms:\n",
    "# d = {}\n",
    "# for dataset in dataset_names:\n",
    "#     recoreds = grouped_records.filter_equals(\"dataset, algorithm\", (dataset, 'D'))\n",
    "#     # assert  == 'DANN':\n",
    "#     if len(recoreds) != 60:\n",
    "#         print(len(recoreds), 'DANN', dataset)\n",
    "#         for rec in recoreds:\n",
    "#             print(len(rec['records']))\n",
    "#             for r in rec['records']:\n",
    "#                 assert r['args']['algorithm'] == 'DANN'\n",
    "#                 print(r['args']['output_dir'])\n",
    "#                 dir = r['args']['output_dir']\n",
    "#                 try:\n",
    "#                     shutil.rmtree(dir)\n",
    "#                     print(dir)\n",
    "#                 except:\n",
    "#                     pass\n",
    "    # print(len(grouped_records[0]['records']))\n",
    "    # print(grouped_records[0]['output_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip\n",
      "\n",
      "ERM                       & 80.8 $\\pm$ 0.4            & 93.0 $\\pm$ 0.7            & 77.3 $\\pm$ 1.6            & 42.2 $\\pm$ 5.5            & 73.4                      \\\\\n",
      "\\midrule\n",
      "\n",
      "CORAL                     & X                         & 87.4 $\\pm$ 0.0            & 77.5 $\\pm$ 1.0            & 40.3 $\\pm$ 4.4            & X                         \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    print(backbone)\n",
    "    for algorithm in algorithms:\n",
    "        table = [[None for _ in [*dataset_names, \"Avg\"]] for _ in adaptation_names]\n",
    "        model_names = []\n",
    "        for i, adapt_method in enumerate(adaptation_names):\n",
    "            means = []\n",
    "            if i == 0:\n",
    "                model_names.append(algorithm)\n",
    "            else:\n",
    "                model_names.append('+'+adapt_method)\n",
    "            for j, dataset in enumerate(dataset_names):\n",
    "                trial_averages = (grouped_records\n",
    "                    .filter_equals(\n",
    "                        \"dataset, adapt, backbone, algorithm\",\n",
    "                        (dataset, adapt_method, backbone, algorithm)\n",
    "                    ).group(\"trial_seed\")\n",
    "                    .map(lambda trial_seed, group:\n",
    "                        group.select(\"sweep_acc\").mean()\n",
    "                    )\n",
    "                )\n",
    "                mean, err, table[i][j] = format_mean(trial_averages, latex)\n",
    "                means.append(mean)\n",
    "            if None in means:\n",
    "                table[i][-1] = \"X\"\n",
    "            else:\n",
    "                table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "                a = grouped_records.filter_equals(\"adapt, backbone, algorithm\", ('None', backbone, algorithm)).filter_in('dataset', tgt_dataset_names).select('sweep_acc')\n",
    "                b = grouped_records.filter_equals(\"adapt, backbone, algorithm\", (adapt_method, backbone, algorithm)).filter_in('dataset', tgt_dataset_names).select('sweep_acc')\n",
    "                if (len(a) == len(b) == 48) & (i != 0):\n",
    "                    p_val = scipy.stats.ttest_rel(a, b, alternative='less')[1]\n",
    "                    if p_val <= 0.01:\n",
    "                        table[i][-1] += '$^{**}$'\n",
    "                    elif p_val <= 0.05:\n",
    "                        table[i][-1] += '$^{*}$'\n",
    "                else:\n",
    "                    # print(len(a), len(b))\n",
    "                    pass \n",
    "        # for i, adapt_method in enumerate(adaptation_names):\n",
    "        #     for j, dataset in enumerate(dataset_names):\n",
    "        #         try:\n",
    "        #             val = float(table[i][j].split(' ')[0])\n",
    "        #             base_val = float(table[0][j].split(' ')[0])\n",
    "        #             if val > base_val:\n",
    "        #                 table[i][j] = '\\\\textbf{' + table[i][j] + '}'\n",
    "        #         except:\n",
    "        #             pass\n",
    "\n",
    "        col_labels = [\"Models\", *dataset_names, \"Avg\"]\n",
    "        header_text = f\"Averages, backbone: {algorithm}\"\n",
    "        custom_print_table(table, header_text, model_names, col_labels, colwidth=25,\n",
    "            latex=latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_names = Q(records).select(\"args.hparams.backbone\").unique()\n",
    "# alg_names = ([n for n in algorithms.ALGORITHMS if n in alg_names] +\n",
    "#     [n for n in alg_names if n not in algorithms.ALGORITHMS])\n",
    "print(backbone_names)\n",
    "# read dataset names and sort (lexicographic order)\n",
    "dataset_names = Q(records).select(\"args.dataset\").unique().sorted()\n",
    "dataset_names = [d for d in datasets.DATASETS if d in dataset_names]\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    if latex:\n",
    "        print()\n",
    "        print(\"\\\\subsubsection{{{}}}\".format(dataset))\n",
    "    test_envs = range(datasets.num_environments(dataset))\n",
    "\n",
    "    table = [[None for _ in [*test_envs, \"Avg\"]] for _ in backbone_names]\n",
    "    for i, backbone in enumerate(backbone_names):\n",
    "        means = []\n",
    "        for j, test_env in enumerate(test_envs):\n",
    "            trial_accs = (grouped_records\n",
    "                .filter_equals(\n",
    "                    \"dataset, backbone, test_env\",\n",
    "                    (dataset, backbone, test_env)\n",
    "                ).select(\"sweep_acc\"))\n",
    "            mean, err, table[i][j] = format_mean(trial_accs, latex)\n",
    "            means.append(mean)\n",
    "        if None in means:\n",
    "            table[i][-1] = \"X\"\n",
    "        else:\n",
    "            table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "\n",
    "    col_labels = [\n",
    "        \"Backbone\", \n",
    "        *datasets.get_dataset_class(dataset).ENVIRONMENTS,\n",
    "        \"Avg\"\n",
    "    ]\n",
    "    header_text = (f\"Dataset: {dataset}, \"\n",
    "        f\"model selection method: {selection_method.name}\")\n",
    "    print_table(table, header_text, backbone_names, list(col_labels),\n",
    "        colwidth=20, latex=latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4608eae2835f79d5a53bc6b12e0a66da51d562043bb25a91ae21208ab2cf5c0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
